{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import config \n",
    "import sql_con\n",
    "from requests import Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get module variables\n",
    "ROOT_DIR = config.ROOT_DIR\n",
    "select_records = sql_con.select_records\n",
    "insert_records = sql_con.insert_records\n",
    "update_records = sql_con.update_records\n",
    "conn_odbc = sql_con.conn_odbc\n",
    "read_contents = sql_con.read_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make request to cryptocompare api to get historical data for bitcoin quote prices in USD\n",
    "url = \"https://min-api.cryptocompare.com/data/histoday\"\n",
    "parameters = {\n",
    "  \"fsym\": \"BTC\",\n",
    "  \"tsym\":\"USD\",\n",
    "  \"allData\":\"true\"\n",
    "}\n",
    "headers = {\n",
    "  \"authorization\": f\"Apikey {config.API_KEY}\",\n",
    "}\n",
    "\n",
    "session = Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "try:\n",
    "  response = session.get(url, params=parameters)\n",
    "  res_json = json.loads(response.text)\n",
    "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "  print(e)\n",
    "\n",
    "# res1 = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture data from reponse and write to json file (ingestion layer)\n",
    "data = res_json[\"Data\"]\n",
    "with open(rf\"{ROOT_DIR}\\data\\btc_api_data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark session start to begin transforming data (processing layer)\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"crypto_analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for data\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"time\", LongType(), True),\n",
    "    StructField(\"close\", DoubleType(), True),\n",
    "    StructField(\"high\", DoubleType(), True),\n",
    "    StructField(\"low\", DoubleType(), True),\n",
    "    StructField(\"open\", DoubleType(), True),\n",
    "    StructField(\"volumefrom\", DoubleType(), True),\n",
    "    StructField(\"volumeto\", DoubleType(), True),\n",
    "    StructField(\"conversionType\", StringType(), True),\n",
    "    StructField(\"conversionSymbol\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------+-------+-------+-------+----------+----------+--------+\n",
      "|  close|conversionSymbol|conversionType|   high|    low|   open|      time|volumefrom|volumeto|\n",
      "+-------+----------------+--------------+-------+-------+-------+----------+----------+--------+\n",
      "|0.04951|                |        direct|0.04951|0.04951|0.04951|1279324800|      20.0|  0.9902|\n",
      "|0.08584|                |        direct|0.08585|0.05941|0.04951|1279411200|     75.01|   5.092|\n",
      "| 0.0808|                |        direct|0.09307|0.07723|0.08584|1279497600|     574.0|   49.66|\n",
      "|0.07474|                |        direct|0.08181|0.07426| 0.0808|1279584000|     262.0|   20.59|\n",
      "|0.07921|                |        direct|0.07921|0.06634|0.07474|1279670400|     575.0|   42.26|\n",
      "| 0.0505|                |        direct|0.08181| 0.0505|0.07921|1279756800|    2160.0|  129.78|\n",
      "|0.06262|                |        direct|0.06767| 0.0505| 0.0505|1279843200|    2402.5|  141.07|\n",
      "|0.05454|                |        direct|0.06161|0.05049|0.06262|1279929600|    496.32|   26.73|\n",
      "| 0.0505|                |        direct|0.05941| 0.0505|0.05454|1280016000|   1551.48|   85.06|\n",
      "|  0.056|                |        direct|  0.056|   0.05| 0.0505|1280102400|     877.0|   46.91|\n",
      "+-------+----------------+--------------+-------+-------+-------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read ingested json file and print out first 10 records\n",
    "df = spark.read.option(\"schema\", schema).json(rf\"{ROOT_DIR}/data/btc_api_data.json\")\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ingestion date as current unix epoch time\n",
    "# write data to csv file after adding ingestion date (csv ingestion point for data pipeline)\n",
    "from pyspark.sql.functions import unix_timestamp, current_timestamp, from_unixtime, col, date_format\n",
    "\n",
    "df = df.withColumn(\"ingestion_date (unix epoch)\", unix_timestamp()).withColumnRenamed(\"time\", \"time (unix epoch)\")\n",
    "df.write.mode(\"overwrite\").csv(rf\"{ROOT_DIR}/data/btc_price.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|close  |conversionSymbol|conversionType|high   |low    |open   |time (unix epoch)|volumefrom|volumeto|ingestion_date (unix epoch)|\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|0.04951|null            |direct        |0.04951|0.04951|0.04951|1279324800       |20.0      |0.9902  |1680479765                 |\n",
      "|0.08584|null            |direct        |0.08585|0.05941|0.04951|1279411200       |75.01     |5.092   |1680479765                 |\n",
      "|0.0808 |null            |direct        |0.09307|0.07723|0.08584|1279497600       |574.0     |49.66   |1680479765                 |\n",
      "|0.07474|null            |direct        |0.08181|0.07426|0.0808 |1279584000       |262.0     |20.59   |1680479765                 |\n",
      "|0.07921|null            |direct        |0.07921|0.06634|0.07474|1279670400       |575.0     |42.26   |1680479765                 |\n",
      "|0.0505 |null            |direct        |0.08181|0.0505 |0.07921|1279756800       |2160.0    |129.78  |1680479765                 |\n",
      "|0.06262|null            |direct        |0.06767|0.0505 |0.0505 |1279843200       |2402.5    |141.07  |1680479765                 |\n",
      "|0.05454|null            |direct        |0.06161|0.05049|0.06262|1279929600       |496.32    |26.73   |1680479765                 |\n",
      "|0.0505 |null            |direct        |0.05941|0.0505 |0.05454|1280016000       |1551.48   |85.06   |1680479765                 |\n",
      "|0.056  |null            |direct        |0.056  |0.05   |0.0505 |1280102400       |877.0     |46.91   |1680479765                 |\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read from ingested csv file and print out first 10 records\n",
    "df = spark.read.csv(rf\"{ROOT_DIR}/data/btc_price.csv\", header=True)\n",
    "df.show(n=10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|close  |conversionSymbol|conversionType|high   |low    |open   |time (unix epoch)|volumefrom|volumeto|ingestion_date (unix epoch)|\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|0.04951|null            |direct        |0.04951|0.04951|0.04951|1279324800       |20.0      |0.9902  |1680479765                 |\n",
      "|0.08584|null            |direct        |0.08585|0.05941|0.04951|1279411200       |75.01     |5.092   |1680479765                 |\n",
      "|0.0808 |null            |direct        |0.09307|0.07723|0.08584|1279497600       |574.0     |49.66   |1680479765                 |\n",
      "|0.07474|null            |direct        |0.08181|0.07426|0.0808 |1279584000       |262.0     |20.59   |1680479765                 |\n",
      "|0.07921|null            |direct        |0.07921|0.06634|0.07474|1279670400       |575.0     |42.26   |1680479765                 |\n",
      "|0.0505 |null            |direct        |0.08181|0.0505 |0.07921|1279756800       |2160.0    |129.78  |1680479765                 |\n",
      "|0.06262|null            |direct        |0.06767|0.0505 |0.0505 |1279843200       |2402.5    |141.07  |1680479765                 |\n",
      "|0.05454|null            |direct        |0.06161|0.05049|0.06262|1279929600       |496.32    |26.73   |1680479765                 |\n",
      "|0.0505 |null            |direct        |0.05941|0.0505 |0.05454|1280016000       |1551.48   |85.06   |1680479765                 |\n",
      "|0.056  |null            |direct        |0.056  |0.05   |0.0505 |1280102400       |877.0     |46.91   |1680479765                 |\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract necessary columns\n",
    "df = df.select([\"time (unix epoch)\", \"open\", \"close\", \"high\", \"low\", \"volumefrom\", \"volumeto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time (unix epoch)', 'string'),\n",
       " ('open', 'string'),\n",
       " ('close', 'string'),\n",
       " ('high', 'string'),\n",
       " ('low', 'string'),\n",
       " ('volumefrom', 'string'),\n",
       " ('volumeto', 'string')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time (unix epoch): string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- close: string (nullable = true)\n",
      " |-- high: string (nullable = true)\n",
      " |-- low: string (nullable = true)\n",
      " |-- volumefrom: string (nullable = true)\n",
      " |-- volumeto: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+------------------+--------------------+\n",
      "|summary|             open|             close|              high|              low|        volumefrom|            volumeto|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+--------------------+\n",
      "|  count|             4643|              4643|              4643|             4643|              4643|                4643|\n",
      "|   mean|8880.602872302385|  8886.67325578074| 9122.189641488276|8612.653696144727|53761.577872065376|4.5704536163200855E8|\n",
      "| stddev|14496.22260263107|14498.411483115498|14886.111362812839|14052.53673852626| 48761.98430856715| 8.097913929815264E8|\n",
      "|    min|          0.04951|           0.04951|           0.04951|             0.01|               0.0|                 0.0|\n",
      "|    max|          9999.93|           9999.93|            9990.4|           999.73|          99812.97|          9999594.97|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get descriptive statistics for numeric columns\n",
    "df.describe([\"open\", \"close\", \"high\", \"low\", \"volumefrom\", \"volumeto\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------+-------+-------+----------+--------+\n",
      "|time (unix epoch)|   open|  close|   high|    low|volumefrom|volumeto|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+\n",
      "|       1279324800|0.04951|0.04951|0.04951|0.04951|      20.0|  0.9902|\n",
      "|       1279411200|0.04951|0.08584|0.08585|0.05941|     75.01|   5.092|\n",
      "|       1279497600|0.08584| 0.0808|0.09307|0.07723|     574.0|   49.66|\n",
      "|       1279584000| 0.0808|0.07474|0.08181|0.07426|     262.0|   20.59|\n",
      "|       1279670400|0.07474|0.07921|0.07921|0.06634|     575.0|   42.26|\n",
      "|       1279756800|0.07921| 0.0505|0.08181| 0.0505|    2160.0|  129.78|\n",
      "|       1279843200| 0.0505|0.06262|0.06767| 0.0505|    2402.5|  141.07|\n",
      "|       1279929600|0.06262|0.05454|0.06161|0.05049|    496.32|   26.73|\n",
      "|       1280016000|0.05454| 0.0505|0.05941| 0.0505|   1551.48|   85.06|\n",
      "|       1280102400| 0.0505|  0.056|  0.056|   0.05|     877.0|   46.91|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set spark session timezone to UTC to have a uniform reference point for all date related fields\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "df = df.withColumn(\"date_time (unix)\", from_unixtime(\"time (unix epoch)\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "spark.conf.unset(\"spark.sql.session.timeZone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+-------------------+\n",
      "|time (unix epoch)|open   |close  |high   |low    |volumefrom|volumeto|date_time (unix)   |date_time          |\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+-------------------+\n",
      "|1279324800       |0.04951|0.04951|0.04951|0.04951|20.0      |0.9902  |2010-07-17 00:00:00|2010-07-16 20:00:00|\n",
      "|1279411200       |0.04951|0.08584|0.08585|0.05941|75.01     |5.092   |2010-07-18 00:00:00|2010-07-17 20:00:00|\n",
      "|1279497600       |0.08584|0.0808 |0.09307|0.07723|574.0     |49.66   |2010-07-19 00:00:00|2010-07-18 20:00:00|\n",
      "|1279584000       |0.0808 |0.07474|0.08181|0.07426|262.0     |20.59   |2010-07-20 00:00:00|2010-07-19 20:00:00|\n",
      "|1279670400       |0.07474|0.07921|0.07921|0.06634|575.0     |42.26   |2010-07-21 00:00:00|2010-07-20 20:00:00|\n",
      "|1279756800       |0.07921|0.0505 |0.08181|0.0505 |2160.0    |129.78  |2010-07-22 00:00:00|2010-07-21 20:00:00|\n",
      "|1279843200       |0.0505 |0.06262|0.06767|0.0505 |2402.5    |141.07  |2010-07-23 00:00:00|2010-07-22 20:00:00|\n",
      "|1279929600       |0.06262|0.05454|0.06161|0.05049|496.32    |26.73   |2010-07-24 00:00:00|2010-07-23 20:00:00|\n",
      "|1280016000       |0.05454|0.0505 |0.05941|0.0505 |1551.48   |85.06   |2010-07-25 00:00:00|2010-07-24 20:00:00|\n",
      "|1280102400       |0.0505 |0.056  |0.056  |0.05   |877.0     |46.91   |2010-07-26 00:00:00|2010-07-25 20:00:00|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# timezone will default to system timezone (Easter Standard Time) in absence of specific spark.sql.session.timeZone setting\n",
    "df.withColumn(\"date_time\", from_unixtime(\"time (unix epoch)\", \"yyyy-MM-dd HH:mm:ss\")).show(n=10, truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+---------------------+\n",
      "|time (unix epoch)|open   |close  |high   |low    |volumefrom|volumeto|date_time (unix)   |HV Ratiio            |\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+---------------------+\n",
      "|1279324800       |0.04951|0.04951|0.04951|0.04951|20.0      |0.9902  |2010-07-17 00:00:00|0.0024755            |\n",
      "|1279411200       |0.04951|0.08584|0.08585|0.05941|75.01     |5.092   |2010-07-18 00:00:00|0.001144514064791361 |\n",
      "|1279497600       |0.08584|0.0808 |0.09307|0.07723|574.0     |49.66   |2010-07-19 00:00:00|1.6214285714285715E-4|\n",
      "|1279584000       |0.0808 |0.07474|0.08181|0.07426|262.0     |20.59   |2010-07-20 00:00:00|3.122519083969465E-4 |\n",
      "|1279670400       |0.07474|0.07921|0.07921|0.06634|575.0     |42.26   |2010-07-21 00:00:00|1.3775652173913044E-4|\n",
      "|1279756800       |0.07921|0.0505 |0.08181|0.0505 |2160.0    |129.78  |2010-07-22 00:00:00|3.7875E-5            |\n",
      "|1279843200       |0.0505 |0.06262|0.06767|0.0505 |2402.5    |141.07  |2010-07-23 00:00:00|2.8166493236212278E-5|\n",
      "|1279929600       |0.06262|0.05454|0.06161|0.05049|496.32    |26.73   |2010-07-24 00:00:00|1.2413362346872986E-4|\n",
      "|1280016000       |0.05454|0.0505 |0.05941|0.0505 |1551.48   |85.06   |2010-07-25 00:00:00|3.829246912625364E-5 |\n",
      "|1280102400       |0.0505 |0.056  |0.056  |0.05   |877.0     |46.91   |2010-07-26 00:00:00|6.385404789053591E-5 |\n",
      "|1280188800       |0.056  |0.06   |0.0605 |0.053  |3373.69   |196.92  |2010-07-27 00:00:00|1.7932886542628395E-5|\n",
      "|1280275200       |0.06   |0.0589 |0.062  |0.054  |4390.29   |255.76  |2010-07-28 00:00:00|1.4122073940445847E-5|\n",
      "|1280361600       |0.0589 |0.0699 |0.0699 |0.0571 |8058.49   |528.32  |2010-07-29 00:00:00|8.67408162075029E-6  |\n",
      "|1280448000       |0.0699 |0.0627 |0.0698 |0.0582 |3020.85   |198.53  |2010-07-30 00:00:00|2.3106079414734265E-5|\n",
      "|1280534400       |0.0627 |0.06785|0.06889|0.056  |4022.25   |243.9   |2010-07-31 00:00:00|1.7127229784324696E-5|\n",
      "|1280620800       |0.06785|0.0611 |0.065  |0.06   |2601.0    |162.65  |2010-08-01 00:00:00|2.499038831218762E-5 |\n",
      "|1280707200       |0.0611 |0.06   |0.0633 |0.06   |3599.0    |221.2   |2010-08-02 00:00:00|1.758821894970825E-5 |\n",
      "|1280793600       |0.06   |0.06   |0.065  |0.059  |9821.46   |606.05  |2010-08-03 00:00:00|6.618160640067771E-6 |\n",
      "|1280880000       |0.06   |0.057  |0.06231|0.057  |3494.0    |210.77  |2010-08-04 00:00:00|1.783342873497424E-5 |\n",
      "|1280966400       |0.057  |0.061  |0.061  |0.058  |5034.07   |303.61  |2010-08-05 00:00:00|1.2117431819581373E-5|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"HV Ratiio\", df[\"high\"]/df[\"volumefrom\"])\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+--------+--------+----------+---------------+-------------------+-------------------+\n",
      "|time (unix epoch)|open    |close   |high    |low     |volumefrom|volumeto       |date_time (unix)   |HV Ratiio          |\n",
      "+-----------------+--------+--------+--------+--------+----------+---------------+-------------------+-------------------+\n",
      "|1680393600       |28465.3 |28204.02|28538.36|27880.95|24746.49  |6.9881659115E8 |2023-04-02 00:00:00|1.1532285992882223 |\n",
      "|1680307200       |28477.29|28465.3 |28810.95|28265.42|19774.03  |5.6329940551E8 |2023-04-01 00:00:00|1.4570095220852806 |\n",
      "|1680220800       |28037.46|28477.29|28650.47|27541.23|50916.39  |1.43674028379E9|2023-03-31 00:00:00|0.5626964126875452 |\n",
      "|1680134400       |28355.87|28037.46|29172.9 |27731.64|63033.78  |1.79002247511E9|2023-03-30 00:00:00|0.4628137484377425 |\n",
      "|1680048000       |27274.9 |28355.87|28640.99|27261.75|52216.18  |1.47107639838E9|2023-03-29 00:00:00|0.5485079528988908 |\n",
      "|1679961600       |27145.09|27274.9 |27501.44|26660.19|38686.66  |1.04655123393E9|2023-03-28 00:00:00|0.7108765657205868 |\n",
      "|1679875200       |27996.81|27145.09|28044.15|26565.75|48705.37  |1.33245454599E9|2023-03-27 00:00:00|0.5757917453455338 |\n",
      "|1679788800       |27493.43|27996.81|28212.64|27447.43|29291.76  |8.1518627578E8 |2023-03-26 00:00:00|0.9631596052951411 |\n",
      "|1679702400       |27491.73|27493.43|27810.74|27188.56|26897.42  |7.3983581014E8 |2023-03-25 00:00:00|1.0339556730719899 |\n",
      "|1679616000       |28345.69|27491.73|28417.0 |27047.96|56653.76  |1.58051710941E9|2023-03-24 00:00:00|0.5015907152499675 |\n",
      "|1679529600       |27317.37|28345.69|28810.23|27188.53|69232.03  |1.93823226808E9|2023-03-23 00:00:00|0.4161401882914599 |\n",
      "|1679443200       |28185.99|27317.37|28877.16|26681.65|85640.26  |2.40026112773E9|2023-03-22 00:00:00|0.3371914097411661 |\n",
      "|1679356800       |27807.29|28185.99|28498.09|27411.61|47709.66  |1.33896560135E9|2023-03-21 00:00:00|0.5973232674473051 |\n",
      "|1679270400       |28037.32|27807.29|28534.79|27229.43|65776.48  |1.83705337408E9|2023-03-20 00:00:00|0.43381448809665707|\n",
      "|1679184000       |26973.38|28037.32|28448.08|26902.0 |48141.92  |1.33730393931E9|2023-03-19 00:00:00|0.5909211763884781 |\n",
      "|1679097600       |27440.55|26973.38|27746.59|26658.45|48417.21  |1.32401989623E9|2023-03-18 00:00:00|0.5730728804902224 |\n",
      "|1679011200       |25051.31|27440.55|27784.36|24945.47|96356.43  |2.55314278058E9|2023-03-17 00:00:00|0.288349827821558  |\n",
      "|1678924800       |24369.16|25051.31|25210.61|24221.04|55375.79  |1.37214704917E9|2023-03-16 00:00:00|0.4552641145164701 |\n",
      "|1678838400       |24758.71|24369.16|25249.88|23950.43|74030.83  |1.82429987463E9|2023-03-15 00:00:00|0.3410724964180464 |\n",
      "|1678752000       |24205.82|24758.71|26507.17|24084.6 |109089.41 |2.74410290012E9|2023-03-14 00:00:00|0.24298573069558263|\n",
      "+-----------------+--------+--------+--------+--------+----------+---------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort by date_time (unix) in descending order to get HV Ratiio for most recent dates\n",
    "df2.sort(\"date_time (unix)\", ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c62ecade22fff4c1d31446e36615b3ce67a81b5933d46e8d3b7993b34a0b8fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
