{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import config \n",
    "import sql_con\n",
    "from requests import Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get module variables\n",
    "ROOT_DIR = config.ROOT_DIR\n",
    "select_records = sql_con.select_records\n",
    "insert_records = sql_con.insert_records\n",
    "update_records = sql_con.update_records\n",
    "conn_odbc = sql_con.conn_odbc\n",
    "read_contents = sql_con.read_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make request to cryptocompare api to get historical data for bitcoin quote prices in USD\n",
    "url = \"https://min-api.cryptocompare.com/data/histoday\"\n",
    "parameters = {\n",
    "  \"fsym\": \"BTC\",\n",
    "  \"tsym\":\"USD\",\n",
    "  \"allData\":\"true\"\n",
    "}\n",
    "headers = {\n",
    "  \"authorization\": f\"Apikey {config.API_KEY}\",\n",
    "}\n",
    "\n",
    "session = Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "try:\n",
    "  response = session.get(url, params=parameters)\n",
    "  res_json = json.loads(response.text)\n",
    "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "  print(e)\n",
    "\n",
    "# res1 = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture data from reponse and write to json file (ingestion layer)\n",
    "data = res_json[\"Data\"]\n",
    "with open(rf\"{ROOT_DIR}\\data\\btc_api_data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark session start to begin transforming data (processing layer)\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"crypto_analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for data\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"time\", LongType(), True),\n",
    "    StructField(\"close\", DoubleType(), True),\n",
    "    StructField(\"high\", DoubleType(), True),\n",
    "    StructField(\"low\", DoubleType(), True),\n",
    "    StructField(\"open\", DoubleType(), True),\n",
    "    StructField(\"volumefrom\", DoubleType(), True),\n",
    "    StructField(\"volumeto\", DoubleType(), True),\n",
    "    StructField(\"conversionType\", StringType(), True),\n",
    "    StructField(\"conversionSymbol\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------+-------+-------+-------+----------+----------+--------+\n",
      "|  close|conversionSymbol|conversionType|   high|    low|   open|      time|volumefrom|volumeto|\n",
      "+-------+----------------+--------------+-------+-------+-------+----------+----------+--------+\n",
      "|0.04951|                |        direct|0.04951|0.04951|0.04951|1279324800|      20.0|  0.9902|\n",
      "|0.08584|                |        direct|0.08585|0.05941|0.04951|1279411200|     75.01|   5.092|\n",
      "| 0.0808|                |        direct|0.09307|0.07723|0.08584|1279497600|     574.0|   49.66|\n",
      "|0.07474|                |        direct|0.08181|0.07426| 0.0808|1279584000|     262.0|   20.59|\n",
      "|0.07921|                |        direct|0.07921|0.06634|0.07474|1279670400|     575.0|   42.26|\n",
      "| 0.0505|                |        direct|0.08181| 0.0505|0.07921|1279756800|    2160.0|  129.78|\n",
      "|0.06262|                |        direct|0.06767| 0.0505| 0.0505|1279843200|    2402.5|  141.07|\n",
      "|0.05454|                |        direct|0.06161|0.05049|0.06262|1279929600|    496.32|   26.73|\n",
      "| 0.0505|                |        direct|0.05941| 0.0505|0.05454|1280016000|   1551.48|   85.06|\n",
      "|  0.056|                |        direct|  0.056|   0.05| 0.0505|1280102400|     877.0|   46.91|\n",
      "+-------+----------------+--------------+-------+-------+-------+----------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read ingested json file and print out first 10 records\n",
    "df = spark.read.option(\"schema\", schema).json(rf\"{ROOT_DIR}/data/btc_api_data.json\")\n",
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ingestion date as current unix epoch time\n",
    "# write data to csv file after adding ingestion date (csv ingestion point for data pipeline)\n",
    "from pyspark.sql.functions import unix_timestamp, current_timestamp, from_unixtime, col, date_format\n",
    "\n",
    "df = df.withColumn(\"ingestion_date (unix epoch)\", unix_timestamp()).withColumnRenamed(\"time\", \"time (unix epoch)\")\n",
    "df.write.mode(\"overwrite\").csv(rf\"{ROOT_DIR}/data/btc_price.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|close  |conversionSymbol|conversionType|high   |low    |open   |time (unix epoch)|volumefrom|volumeto|ingestion_date (unix epoch)|\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|0.04951|null            |direct        |0.04951|0.04951|0.04951|1279324800       |20.0      |0.9902  |1680314368                 |\n",
      "|0.08584|null            |direct        |0.08585|0.05941|0.04951|1279411200       |75.01     |5.092   |1680314368                 |\n",
      "|0.0808 |null            |direct        |0.09307|0.07723|0.08584|1279497600       |574.0     |49.66   |1680314368                 |\n",
      "|0.07474|null            |direct        |0.08181|0.07426|0.0808 |1279584000       |262.0     |20.59   |1680314368                 |\n",
      "|0.07921|null            |direct        |0.07921|0.06634|0.07474|1279670400       |575.0     |42.26   |1680314368                 |\n",
      "|0.0505 |null            |direct        |0.08181|0.0505 |0.07921|1279756800       |2160.0    |129.78  |1680314368                 |\n",
      "|0.06262|null            |direct        |0.06767|0.0505 |0.0505 |1279843200       |2402.5    |141.07  |1680314368                 |\n",
      "|0.05454|null            |direct        |0.06161|0.05049|0.06262|1279929600       |496.32    |26.73   |1680314368                 |\n",
      "|0.0505 |null            |direct        |0.05941|0.0505 |0.05454|1280016000       |1551.48   |85.06   |1680314368                 |\n",
      "|0.056  |null            |direct        |0.056  |0.05   |0.0505 |1280102400       |877.0     |46.91   |1680314368                 |\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read from ingested csv file and print out first 10 records\n",
    "df = spark.read.csv(rf\"{ROOT_DIR}/data/btc_price.csv\", header=True)\n",
    "df.show(n=10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|close  |conversionSymbol|conversionType|high   |low    |open   |time (unix epoch)|volumefrom|volumeto|ingestion_date (unix epoch)|\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "|0.04951|null            |direct        |0.04951|0.04951|0.04951|1279324800       |20.0      |0.9902  |1680314368                 |\n",
      "|0.08584|null            |direct        |0.08585|0.05941|0.04951|1279411200       |75.01     |5.092   |1680314368                 |\n",
      "|0.0808 |null            |direct        |0.09307|0.07723|0.08584|1279497600       |574.0     |49.66   |1680314368                 |\n",
      "|0.07474|null            |direct        |0.08181|0.07426|0.0808 |1279584000       |262.0     |20.59   |1680314368                 |\n",
      "|0.07921|null            |direct        |0.07921|0.06634|0.07474|1279670400       |575.0     |42.26   |1680314368                 |\n",
      "|0.0505 |null            |direct        |0.08181|0.0505 |0.07921|1279756800       |2160.0    |129.78  |1680314368                 |\n",
      "|0.06262|null            |direct        |0.06767|0.0505 |0.0505 |1279843200       |2402.5    |141.07  |1680314368                 |\n",
      "|0.05454|null            |direct        |0.06161|0.05049|0.06262|1279929600       |496.32    |26.73   |1680314368                 |\n",
      "|0.0505 |null            |direct        |0.05941|0.0505 |0.05454|1280016000       |1551.48   |85.06   |1680314368                 |\n",
      "|0.056  |null            |direct        |0.056  |0.05   |0.0505 |1280102400       |877.0     |46.91   |1680314368                 |\n",
      "+-------+----------------+--------------+-------+-------+-------+-----------------+----------+--------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract necessary columns\n",
    "df = df.select([\"time (unix epoch)\", \"open\", \"close\", \"high\", \"low\", \"volumefrom\", \"volumeto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time (unix epoch)', 'string'),\n",
       " ('open', 'string'),\n",
       " ('close', 'string'),\n",
       " ('high', 'string'),\n",
       " ('low', 'string'),\n",
       " ('volumefrom', 'string'),\n",
       " ('volumeto', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time (unix epoch): string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- close: string (nullable = true)\n",
      " |-- high: string (nullable = true)\n",
      " |-- low: string (nullable = true)\n",
      " |-- volumefrom: string (nullable = true)\n",
      " |-- volumeto: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|             open|             close|              high|               low|        volumefrom|           volumeto|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|             4642|              4642|              4642|              4642|              4642|               4642|\n",
      "|   mean|8876.383850947861| 8882.541059153378|  9117.96708432358| 8608.536443601888|53763.522669108046|4.568706471085794E8|\n",
      "| stddev|14494.93308082456|14497.239565603999|14884.933643762153|14051.250867467425|48768.866780672666|8.098787920402381E8|\n",
      "|    min|          0.04951|           0.04951|           0.04951|              0.01|               0.0|                0.0|\n",
      "|    max|          9999.93|           9999.93|            9990.4|            999.73|          99812.97|         9999594.97|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get descriptive statistics for numeric columns\n",
    "df.describe([\"open\", \"close\", \"high\", \"low\", \"volumefrom\", \"volumeto\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------+-------+-------+----------+--------+\n",
      "|time (unix epoch)|   open|  close|   high|    low|volumefrom|volumeto|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+\n",
      "|       1279324800|0.04951|0.04951|0.04951|0.04951|      20.0|  0.9902|\n",
      "|       1279411200|0.04951|0.08584|0.08585|0.05941|     75.01|   5.092|\n",
      "|       1279497600|0.08584| 0.0808|0.09307|0.07723|     574.0|   49.66|\n",
      "|       1279584000| 0.0808|0.07474|0.08181|0.07426|     262.0|   20.59|\n",
      "|       1279670400|0.07474|0.07921|0.07921|0.06634|     575.0|   42.26|\n",
      "|       1279756800|0.07921| 0.0505|0.08181| 0.0505|    2160.0|  129.78|\n",
      "|       1279843200| 0.0505|0.06262|0.06767| 0.0505|    2402.5|  141.07|\n",
      "|       1279929600|0.06262|0.05454|0.06161|0.05049|    496.32|   26.73|\n",
      "|       1280016000|0.05454| 0.0505|0.05941| 0.0505|   1551.48|   85.06|\n",
      "|       1280102400| 0.0505|  0.056|  0.056|   0.05|     877.0|   46.91|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+\n",
      "|time (unix epoch)|open   |close  |high   |low    |volumefrom|volumeto|date_time (unix)   |\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+\n",
      "|1279324800       |0.04951|0.04951|0.04951|0.04951|20.0      |0.9902  |2010-07-17 00:00:00|\n",
      "|1279411200       |0.04951|0.08584|0.08585|0.05941|75.01     |5.092   |2010-07-18 00:00:00|\n",
      "|1279497600       |0.08584|0.0808 |0.09307|0.07723|574.0     |49.66   |2010-07-19 00:00:00|\n",
      "|1279584000       |0.0808 |0.07474|0.08181|0.07426|262.0     |20.59   |2010-07-20 00:00:00|\n",
      "|1279670400       |0.07474|0.07921|0.07921|0.06634|575.0     |42.26   |2010-07-21 00:00:00|\n",
      "|1279756800       |0.07921|0.0505 |0.08181|0.0505 |2160.0    |129.78  |2010-07-22 00:00:00|\n",
      "|1279843200       |0.0505 |0.06262|0.06767|0.0505 |2402.5    |141.07  |2010-07-23 00:00:00|\n",
      "|1279929600       |0.06262|0.05454|0.06161|0.05049|496.32    |26.73   |2010-07-24 00:00:00|\n",
      "|1280016000       |0.05454|0.0505 |0.05941|0.0505 |1551.48   |85.06   |2010-07-25 00:00:00|\n",
      "|1280102400       |0.0505 |0.056  |0.056  |0.05   |877.0     |46.91   |2010-07-26 00:00:00|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set spark session timezone to UTC to have a uniform reference point for all date related fields\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "df.withColumn(\"date_time (unix)\", from_unixtime(\"time (unix epoch)\", \"yyyy-MM-dd HH:mm:ss\")).show(n=10, truncate=False)\n",
    "spark.conf.unset(\"spark.sql.session.timeZone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+\n",
      "|time (unix epoch)|open   |close  |high   |low    |volumefrom|volumeto|date_time          |\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+\n",
      "|1279324800       |0.04951|0.04951|0.04951|0.04951|20.0      |0.9902  |2010-07-16 20:00:00|\n",
      "|1279411200       |0.04951|0.08584|0.08585|0.05941|75.01     |5.092   |2010-07-17 20:00:00|\n",
      "|1279497600       |0.08584|0.0808 |0.09307|0.07723|574.0     |49.66   |2010-07-18 20:00:00|\n",
      "|1279584000       |0.0808 |0.07474|0.08181|0.07426|262.0     |20.59   |2010-07-19 20:00:00|\n",
      "|1279670400       |0.07474|0.07921|0.07921|0.06634|575.0     |42.26   |2010-07-20 20:00:00|\n",
      "|1279756800       |0.07921|0.0505 |0.08181|0.0505 |2160.0    |129.78  |2010-07-21 20:00:00|\n",
      "|1279843200       |0.0505 |0.06262|0.06767|0.0505 |2402.5    |141.07  |2010-07-22 20:00:00|\n",
      "|1279929600       |0.06262|0.05454|0.06161|0.05049|496.32    |26.73   |2010-07-23 20:00:00|\n",
      "|1280016000       |0.05454|0.0505 |0.05941|0.0505 |1551.48   |85.06   |2010-07-24 20:00:00|\n",
      "|1280102400       |0.0505 |0.056  |0.056  |0.05   |877.0     |46.91   |2010-07-25 20:00:00|\n",
      "+-----------------+-------+-------+-------+-------+----------+--------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# timezone will default to system timezone (Easter Standard Time) in absence of specific spark.sql.session.timeZone setting\n",
    "df.withColumn(\"date_time\", from_unixtime(\"time (unix epoch)\", \"yyyy-MM-dd HH:mm:ss\")).show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c62ecade22fff4c1d31446e36615b3ce67a81b5933d46e8d3b7993b34a0b8fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
